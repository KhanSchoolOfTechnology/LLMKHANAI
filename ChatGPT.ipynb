{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "DShIF502VW-N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SlpFcvzJnn5e",
        "outputId": "6c873fee-1bef-41f3-f057-8865aa4cdf32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/76.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m61.4/76.5 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2023.7.22)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Installing collected packages: openai\n",
            "Successfully installed openai-0.28.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CvtDb_yzgjyP"
      },
      "outputs": [],
      "source": [
        "import openai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "khI52JDVJ2EF"
      },
      "source": [
        "# **Translation Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mm9URcJoCvad"
      },
      "outputs": [],
      "source": [
        "def translate_english_to_urdu(text):\n",
        "    openai.api_key = api_key\n",
        "\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\",  # Use the chat model\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant that translates English to Urdu.\"},\n",
        "            {\"role\": \"user\", \"content\": text}\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    translated_text = response['choices'][0]['message']['content'].strip()\n",
        "    return translated_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lPGTFuBlFOPD",
        "outputId": "d41b928d-5704-4125-b5fb-04ef8cfde8da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter an English text to translate to Urdu: My name is Abdullah\n",
            "English: My name is Abdullah\n",
            "Urdu: میرا نام عبداللہ ہے\n"
          ]
        }
      ],
      "source": [
        "# Example usage:\n",
        "english_text = input(\"Enter an English text to translate to Urdu: \")\n",
        "urdu_translation = translate_english_to_urdu(english_text)\n",
        "\n",
        "print(f\"English: {english_text}\")\n",
        "print(f\"Urdu: {urdu_translation}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-5hAt0OKd_B"
      },
      "source": [
        "# **Chatbot**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def chat_with_gpt3(context):\n",
        "    openai.api_key = api_key\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        max_tokens=4000,\n",
        "        messages=context\n",
        "    )\n",
        "    return response['choices'][0]['message']['content'].strip()"
      ],
      "metadata": {
        "id": "K4urF5hxFUAK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "context = [{\"role\": \"system\", \"content\": \"You are a restaurant assistant chatbot. We sell (zinger burger, pizza, chicken tikka pizza, hot wings, nuggets and prices are ($10, $15, $20, $15, and $10)), generate summary as json with variables username, paymentmethod, and address\"}]\n",
        "\n",
        "print(\"OrderBot:\")\n",
        "\n",
        "# Start an interactive loop\n",
        "while True:\n",
        "    user_input = input(\"You: \")\n",
        "    if user_input.lower() == 'exit':\n",
        "        break\n",
        "    else:\n",
        "        # Calculate the current context length\n",
        "        current_context_length = sum(len(message['content']) for message in context)\n",
        "\n",
        "        # Check if adding the user input would exceed the model's limit\n",
        "        if current_context_length + len(user_input) > 4000:\n",
        "            # If it exceeds the limit, create a new context starting with the system message\n",
        "            context = [\n",
        "                {\"role\": \"system\", \"content\": \"You are a restaurant assistant chatbot. We sell (zinger burger, pizza, chicken tikka pizza, hot wings, nuggets and prices are ($10, $15, $20, $15, and $10)), generate summary as json with variables username, paymentmethod, and address\"},\n",
        "                {\"role\": \"user\", \"content\": user_input}\n",
        "            ]\n",
        "\n",
        "        else:\n",
        "            # Add user's message to context\n",
        "            context.append({\"role\": \"user\", \"content\": user_input})\n",
        "\n",
        "        # Get the response from GPT-3\n",
        "        response = chat_with_gpt3(context)\n",
        "\n",
        "        # Add GPT-3's response to context\n",
        "        context.append({\"role\": \"assistant\", \"content\": response})\n",
        "\n",
        "        print(f\"OrderBot: {response}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        },
        "id": "bb1zymH3W2o0",
        "outputId": "6af5ebce-d85c-40c7-e3a8-71f6af586f6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OrderBot:\n",
            "You: hello\n",
            "OrderBot: Hello! How can I assist you today?\n",
            "You: what do you offer\n",
            "OrderBot: We offer a variety of delicious food items including zinger burger, pizza, chicken tikka pizza, hot wings, and nuggets. The prices for these items are as follows: \n",
            "- Zinger Burger: $10\n",
            "- Pizza: $15\n",
            "- Chicken Tikka Pizza: $20\n",
            "- Hot Wings: $15\n",
            "- Nuggets: $10\n",
            "\n",
            "Please let me know if you would like to place an order or have any questions!\n",
            "You: zinger burger and pizza 1 each\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "InvalidRequestError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidRequestError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-60fef80b5231>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m# Get the response from GPT-3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchat_with_gpt3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m# Add GPT-3's response to context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-c09a20e0cf0c>\u001b[0m in \u001b[0;36mchat_with_gpt3\u001b[0;34m(context)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mchat_with_gpt3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mopenai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapi_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     response = openai.ChatCompletion.create(\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gpt-3.5-turbo\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mmax_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_resources/chat_completion.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTryAgain\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_resources/abstract/engine_api_resource.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    151\u001b[0m         )\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         response, _, api_key = requestor.request(\n\u001b[0m\u001b[1;32m    154\u001b[0m             \u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    296\u001b[0m             \u001b[0mrequest_timeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m         )\n\u001b[0;32m--> 298\u001b[0;31m         \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgot_stream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_interpret_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgot_stream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    698\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m             return (\n\u001b[0;32m--> 700\u001b[0;31m                 self._interpret_response_line(\n\u001b[0m\u001b[1;32m    701\u001b[0m                     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m                     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0mstream_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstream\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"error\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstream_error\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mrcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m             raise self.handle_error_response(\n\u001b[0m\u001b[1;32m    766\u001b[0m                 \u001b[0mrbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m             )\n",
            "\u001b[0;31mInvalidRequestError\u001b[0m: This model's maximum context length is 4097 tokens. However, you requested 4198 tokens (198 in the messages, 4000 in the completion). Please reduce the length of the messages or completion."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W2NfI359PN-D"
      },
      "source": [
        "# **Math Chatbot**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9YQ-tPNaRbeg",
        "outputId": "d8a6cbf7-f595-493a-8dcd-d2f5a767586b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mathematics Chatbot: Hello! I can help you with math. Type 'exit' to quit.\n",
            "You: teach me algebra basics\n",
            "Bot: Of course! I'd be happy to teach you the basics of algebra. Algebra is a branch of mathematics that involves using letters and symbols to represent unknown quantities and solve equations. It is important for solving a wide range of mathematical problems.\n",
            "\n",
            "1. Variables: In algebra, we use variables (usually represented by letters) to represent unknown quantities. For example, if we want to find the value of a number, we can use the variable \"x\" to represent it.\n",
            "\n",
            "2. Expressions: An algebraic expression is a combination of variables, numbers, and mathematical operations such as addition, subtraction, multiplication, and division. For example, the expression 2x + 3y represents the sum of 2 times x and 3 times y.\n",
            "\n",
            "3. Equations: An equation is a statement that asserts that two expressions are equal. Equations often involve an unknown variable that we need to solve for. For example, the equation 2x + 5 = 15 states that the sum of 2 times x and 5 is equal to 15. By solving for x, we can find the value of x.\n",
            "\n",
            "4. Solving Equations: To solve an equation, the goal is to isolate the variable on one side of the equation. We do this by performing inverse operations. For example, if we have the equation 3x + 7 = 22, we can start by subtracting 7 from both sides of the equation to get 3x = 15. Then, to isolate x, we divide both sides by 3 to get the solution x = 5.\n",
            "\n",
            "5. Order of Operations: When simplifying expressions or solving equations, it is important to follow the order of operations. The acronym PEMDAS can help you remember the order: Parentheses, Exponents, Multiplication and Division (from left to right), and Addition and Subtraction (from left to right).\n",
            "\n",
            "6. Distributive Property: The distributive property states that multiplying a number by the sum or difference of two other numbers is the same as multiplying that number individually by each of the numbers and then adding or subtracting the results. For example, in the expression 2(x + 3), we can distribute the 2 by multiplying it with both x and 3 to get 2x + 6.\n",
            "\n",
            "These are just some of the basics of algebra. With practice and understanding, you'll be able to solve more complex equations and problems. Let me know if you have any specific questions or if you'd like me to explain something in more detail!\n",
            "You: write three examples\n",
            "Bot: 1) Example of solving a linear equation: Solve the equation 3x + 7 = 22. \n",
            "\n",
            "Solution: \n",
            "To solve this equation, we must isolate the variable x on one side. Start by subtracting 7 from both sides of the equation: \n",
            "3x + 7 - 7 = 22 - 7 \n",
            "3x = 15 \n",
            "\n",
            "Next, divide both sides of the equation by 3 to solve for x: \n",
            "3x/3 = 15/3 \n",
            "x = 5 \n",
            "\n",
            "Therefore, the solution to the equation 3x + 7 = 22 is x = 5.\n",
            "\n",
            "2) Example of finding the area of a rectangle: Find the area of a rectangle with length 8 units and width 5 units. \n",
            "\n",
            "Solution: \n",
            "The formula to find the area of a rectangle is A = length × width. \n",
            "In this case, the length is 8 units and the width is 5 units. \n",
            "Substituting these values into the formula, we have: \n",
            "A = 8 × 5 \n",
            "A = 40 \n",
            "\n",
            "Therefore, the area of the rectangle is 40 square units.\n",
            "\n",
            "3) Example of solving a quadratic equation: Solve the equation x^2 + 6x + 9 = 0. \n",
            "\n",
            "Solution: \n",
            "To solve this quadratic equation, we can factor it or use the quadratic formula. In this case, the equation can be factored as: \n",
            "(x + 3)^2 = 0 \n",
            "\n",
            "Taking the square root of both sides, we have: \n",
            "x + 3 = 0 \n",
            "\n",
            "Next, solve for x by isolating it on one side of the equation: \n",
            "x = -3 \n",
            "\n",
            "Therefore, the solution to the equation x^2 + 6x + 9 = 0 is x = -3.\n",
            "You: give real life two example\n",
            "Bot: Sure, here are two real-life examples that involve math:\n",
            "\n",
            "1) Planning a road trip: When going on a road trip, you need to calculate the distance you will be covering, the estimated time it will take to reach your destination, and the fuel cost. This requires using mathematical calculations to determine the most efficient route, considering factors such as distance, time, and gas mileage. Additionally, you might need to budget your expenses for food, accommodation, and other expenses using math skills such as addition, subtraction, and multiplication.\n",
            "\n",
            "2) Budgeting and personal finance: Managing personal finances involves numerous mathematical calculations. For example, creating a monthly budget requires adding up various sources of income, estimating expenses, and determining how much money will be left over for saving or investing. Similarly, calculating interest rates, understanding compound interest, and comparing financial products like loans or credit cards involves using mathematical formulas and calculations to make informed decisions about borrowing or investing money.\n",
            "You: give me mathematical example of the above\n",
            "Bot: Sure! Here's a mathematical example related to being a math teacher:\n",
            "\n",
            "Let's say you are teaching a class of 30 students and you want to find the average score of their recent math exam. The scores are as follows:\n",
            "\n",
            "85, 92, 78, 90, 88, 95, 76, 82, 91, 84, 89, 93, 86, 79, 83, 87, 90, 87, 91, 88, 81, 85, 86, 84, 92, 89, 88, 85, 87, 93.\n",
            "\n",
            "To find the average score, you would add up all the scores and divide by the number of students:\n",
            "\n",
            "(85 + 92 + 78 + 90 + 88 + 95 + 76 + 82 + 91 + 84 + 89 + 93 + 86 + 79 + 83 + 87 + 90 + 87 + 91 + 88 + 81 + 85 + 86 + 84 + 92 + 89 + 88 + 85 + 87 + 93) / 30\n",
            "\n",
            "= 2635 / 30\n",
            "\n",
            "≈ 87.83\n",
            "\n",
            "So, the average score of the class on the math exam is approximately 87.83.\n",
            "You: exit\n"
          ]
        }
      ],
      "source": [
        "def teach_math(chat_input):\n",
        "    # Define a conversation with the chatbot\n",
        "    conversation = [\n",
        "        {\"role\": \"system\", \"content\": \"You are a math teacher.\"},\n",
        "        {\"role\": \"user\", \"content\": chat_input},\n",
        "    ]\n",
        "\n",
        "    # Generate a response from the chatbot\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=conversation,\n",
        "    )\n",
        "\n",
        "    # Extract and return the chatbot's reply\n",
        "    reply = response['choices'][0]['message']['content']\n",
        "    return reply\n",
        "\n",
        "# Main loop to interact with the chatbot\n",
        "print(\"Mathematics Chatbot: Hello! I can help you with math. Type 'exit' to quit.\")\n",
        "while True:\n",
        "    user_input = input(\"You: \")\n",
        "    if user_input.lower() == 'exit':\n",
        "        break\n",
        "    response = teach_math(user_input)\n",
        "    print(\"Bot:\", response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aiSLhHhOYeUc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AYjwyGJvXWxS"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP3FnbxUDEyuNPQh5xbCK3F"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}